apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-defaults
  namespace: data
data:
  spark-defaults.conf: |
    spark.hadoop.fs.s3a.access.key UgqcuJOvwHYt7VwJWvLw
    spark.hadoop.fs.s3a.secret.key NVveartUpNOGVhbybNk5hbF8xeKJrUxuvv0VottG
    spark.hadoop.fs.s3a.path.style.access true
    spark.hadoop.fs.s3a.endpoint  http://lake-minio.data.svc.cluster.local
    spark.hadoop.fs.s3a.impl org.apache.hadoop.fs.s3a.S3AFileSystem
    spark.hadoop.fs.s3a.bucket.nyc-tlc.endpoint https://s3.us-east-1.amazonaws.com
    spark.hadoop.fs.s3a.bucket.nyc-tlc.aws.credentials.provider org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider
    spark.hadoop.fs.s3a.fast.upload true
    spark.kubernetes.file.upload.path s3a://data-lake/files/

    spark.hadoop.fs.s3a.committer.name directory
    spark.hadoop.parquet.enable.summary-metadata false
    spark.sql.catalogImplementation hive
    spark.hive.metastore.uris thrift://cat-hive-metastore.data.svc.cluster.local:9083

    spark.sql.hive.metastore.version 3.1.2
    spark.sql.hive.metastore.jars /usr/local/share/jars/hive/*
    spark.sql.warehouse.dir /tmp/spark-warehouse

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-bastion
  namespace: data
  labels:
    app.kubernetes.io/name: spark-bastion
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: spark-bastion
  strategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: spark-bastion
    spec:
      volumes:
        - name: conf
          configMap:
            name: spark-defaults
      containers:
        - name: spark-bastion
          image: derivedai/spark:3.0.1-hive-3.1.2-hadoop-3.2.1
          imagePullPolicy: Always
          command: [ "/bin/bash", "-c", "--" ]
          args: [ "while true; do sleep 30; done;" ]
          ports:
            - name: http
              containerPort: 4040
          env:
            - name: POD_UID
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.uid
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
          volumeMounts:
            - mountPath: /opt/spark/conf/spark-defaults.conf
              name: conf
              subPath: spark-defaults.conf